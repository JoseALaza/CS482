# CS482
Data Mining

<div id="course_syllabus" style="margin-bottom: 10px;" class="user_content enhanced">
  <h2 id="books">Books</h2>
<p>There are three axes that data mining intersects: data, methods and systems.</p>
<p><strong>Data &amp; Methods-oriented books:</strong></p>
<ul>
<li>
<p>Main textbook on ML methods:<span>&nbsp;</span><em>“Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow”</em>, 2nd Edition, by Aurélien Géron, 2019.<span>&nbsp;</span><a href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=dp_ob_title_bk" class="external" target="_blank" rel="noreferrer noopener"><span>Amazon</span><span class="external_link_icon" style="margin-inline-start: 5px; " role="presentation"><svg viewBox="0 0 1920 1920" version="1.1" xmlns="http://www.w3.org/2000/svg" style="width:1em; height:1em; vertical-align:middle; fill:currentColor">
    <path d="M1226.66667,267 C1314.88,267 1386.66667,338.786667 1386.66667,427 L1386.66667,427 L1386.66667,853.666667 L1280,853.666667 L1280,693.666667 L106.666667,693.666667 L106.666667,1493.66667 C106.666667,1523 130.56,1547 160,1547 L160,1547 L1226.66667,1547 C1256.10667,1547 1280,1523 1280,1493.66667 L1280,1493.66667 L1280,1280.33333 L1386.66667,1280.33333 L1386.66667,1493.66667 C1386.66667,1581.88 1314.88,1653.66667 1226.66667,1653.66667 L1226.66667,1653.66667 L160,1653.66667 C71.7866667,1653.66667 0,1581.88 0,1493.66667 L0,1493.66667 L0,427 C0,338.786667 71.7866667,267 160,267 L160,267 Z M1584.37333,709.293333 L1904.37333,1029.29333 C1925.17333,1050.09333 1925.17333,1083.90667 1904.37333,1104.70667 L1904.37333,1104.70667 L1584.37333,1424.70667 L1508.96,1349.29333 L1737.86667,1120.38667 L906.613333,1120.38667 L906.613333,1013.72 L1737.86667,1013.72 L1508.96,784.706667 L1584.37333,709.293333 Z M1226.66667,373.666667 L160,373.666667 C130.56,373.666667 106.666667,397.666667 106.666667,427 L106.666667,427 L106.666667,587 L1280,587 L1280,427 C1280,397.666667 1256.10667,373.666667 1226.66667,373.666667 L1226.66667,373.666667 Z" stroke="none" stroke-width="1" fill-rule="evenodd"></path>
</svg>
<span class="screenreader-only">Links to an external site.</span></span></a><span>&nbsp;</span>This book will be referred to as<span>&nbsp;</span><code>GERON</code><span>&nbsp;</span>in the syllabus.</p>
</li>
<li>
<p>Supplemental book on data methods that are not covered by Geron’s book: “Mining of Massive Datasets” by Jure Leskovec, Anand Rajaraman, Jeff Ullman.<span>&nbsp;</span><a href="http://infolab.stanford.edu/~ullman/mmds/bookL.pdf" class="external" target="_blank" rel="noreferrer noopener"><span>Free download</span><span class="external_link_icon" style="margin-inline-start: 5px; " role="presentation"><svg viewBox="0 0 1920 1920" version="1.1" xmlns="http://www.w3.org/2000/svg" style="width:1em; height:1em; vertical-align:middle; fill:currentColor">
    <path d="M1226.66667,267 C1314.88,267 1386.66667,338.786667 1386.66667,427 L1386.66667,427 L1386.66667,853.666667 L1280,853.666667 L1280,693.666667 L106.666667,693.666667 L106.666667,1493.66667 C106.666667,1523 130.56,1547 160,1547 L160,1547 L1226.66667,1547 C1256.10667,1547 1280,1523 1280,1493.66667 L1280,1493.66667 L1280,1280.33333 L1386.66667,1280.33333 L1386.66667,1493.66667 C1386.66667,1581.88 1314.88,1653.66667 1226.66667,1653.66667 L1226.66667,1653.66667 L160,1653.66667 C71.7866667,1653.66667 0,1581.88 0,1493.66667 L0,1493.66667 L0,427 C0,338.786667 71.7866667,267 160,267 L160,267 Z M1584.37333,709.293333 L1904.37333,1029.29333 C1925.17333,1050.09333 1925.17333,1083.90667 1904.37333,1104.70667 L1904.37333,1104.70667 L1584.37333,1424.70667 L1508.96,1349.29333 L1737.86667,1120.38667 L906.613333,1120.38667 L906.613333,1013.72 L1737.86667,1013.72 L1508.96,784.706667 L1584.37333,709.293333 Z M1226.66667,373.666667 L160,373.666667 C130.56,373.666667 106.666667,397.666667 106.666667,427 L106.666667,427 L106.666667,587 L1280,587 L1280,427 C1280,397.666667 1256.10667,373.666667 1226.66667,373.666667 L1226.66667,373.666667 Z" stroke="none" stroke-width="1" fill-rule="evenodd"></path>
</svg>
<span class="screenreader-only">Links to an external site.</span></span></a>. This book will be referred to as<span>&nbsp;</span><code>ULLMAN</code><span>&nbsp;</span>in this syllabus</p>
</li>
</ul>
<p><strong>Systems-oriented books:</strong></p>
<ul>
<li>
<p>Supplemental free book to provide additional input for the engineering / applied aspects of data mining and machine learning today:<span>&nbsp;</span><a href="http://www.mlebook.com/wiki/doku.php" class="external" target="_blank" rel="noreferrer noopener"><span><em>ML Engineering</em></span><span class="external_link_icon" style="margin-inline-start: 5px; " role="presentation"><svg viewBox="0 0 1920 1920" version="1.1" xmlns="http://www.w3.org/2000/svg" style="width:1em; height:1em; vertical-align:middle; fill:currentColor">
    <path d="M1226.66667,267 C1314.88,267 1386.66667,338.786667 1386.66667,427 L1386.66667,427 L1386.66667,853.666667 L1280,853.666667 L1280,693.666667 L106.666667,693.666667 L106.666667,1493.66667 C106.666667,1523 130.56,1547 160,1547 L160,1547 L1226.66667,1547 C1256.10667,1547 1280,1523 1280,1493.66667 L1280,1493.66667 L1280,1280.33333 L1386.66667,1280.33333 L1386.66667,1493.66667 C1386.66667,1581.88 1314.88,1653.66667 1226.66667,1653.66667 L1226.66667,1653.66667 L160,1653.66667 C71.7866667,1653.66667 0,1581.88 0,1493.66667 L0,1493.66667 L0,427 C0,338.786667 71.7866667,267 160,267 L160,267 Z M1584.37333,709.293333 L1904.37333,1029.29333 C1925.17333,1050.09333 1925.17333,1083.90667 1904.37333,1104.70667 L1904.37333,1104.70667 L1584.37333,1424.70667 L1508.96,1349.29333 L1737.86667,1120.38667 L906.613333,1120.38667 L906.613333,1013.72 L1737.86667,1013.72 L1508.96,784.706667 L1584.37333,709.293333 Z M1226.66667,373.666667 L160,373.666667 C130.56,373.666667 106.666667,397.666667 106.666667,427 L106.666667,427 L106.666667,587 L1280,587 L1280,427 C1280,397.666667 1256.10667,373.666667 1226.66667,373.666667 L1226.66667,373.666667 Z" stroke="none" stroke-width="1" fill-rule="evenodd"></path>
</svg>
<span class="screenreader-only">Links to an external site.</span></span></a>, by Andriy Burkov, 2020. Note that the free draft pdf files are at the end of the page.</p>
</li>
<li>
<p>Optional book on data-driven application architectures:<span>&nbsp;</span><em>“Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems”</em>, by Martin Kleppmann,<span>&nbsp;</span><a href="https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable/dp/1449373321" class="external" target="_blank" rel="noreferrer noopener"><span>Amazon</span><span class="external_link_icon" style="margin-inline-start: 5px; " role="presentation"><svg viewBox="0 0 1920 1920" version="1.1" xmlns="http://www.w3.org/2000/svg" style="width:1em; height:1em; vertical-align:middle; fill:currentColor">
    <path d="M1226.66667,267 C1314.88,267 1386.66667,338.786667 1386.66667,427 L1386.66667,427 L1386.66667,853.666667 L1280,853.666667 L1280,693.666667 L106.666667,693.666667 L106.666667,1493.66667 C106.666667,1523 130.56,1547 160,1547 L160,1547 L1226.66667,1547 C1256.10667,1547 1280,1523 1280,1493.66667 L1280,1493.66667 L1280,1280.33333 L1386.66667,1280.33333 L1386.66667,1493.66667 C1386.66667,1581.88 1314.88,1653.66667 1226.66667,1653.66667 L1226.66667,1653.66667 L160,1653.66667 C71.7866667,1653.66667 0,1581.88 0,1493.66667 L0,1493.66667 L0,427 C0,338.786667 71.7866667,267 160,267 L160,267 Z M1584.37333,709.293333 L1904.37333,1029.29333 C1925.17333,1050.09333 1925.17333,1083.90667 1904.37333,1104.70667 L1904.37333,1104.70667 L1584.37333,1424.70667 L1508.96,1349.29333 L1737.86667,1120.38667 L906.613333,1120.38667 L906.613333,1013.72 L1737.86667,1013.72 L1508.96,784.706667 L1584.37333,709.293333 Z M1226.66667,373.666667 L160,373.666667 C130.56,373.666667 106.666667,397.666667 106.666667,427 L106.666667,427 L106.666667,587 L1280,587 L1280,427 C1280,397.666667 1256.10667,373.666667 1226.66667,373.666667 L1226.66667,373.666667 Z" stroke="none" stroke-width="1" fill-rule="evenodd"></path>
</svg>
<span class="screenreader-only">Links to an external site.</span></span></a></p>
</li>
</ul>
<h2 id="schedule">Schedule</h2>
<table>
<thead>
<tr>
<th>Lecture</th>
<th>Description</th>
<th>Reading List</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>We start with an<span>&nbsp;</span><em>introduction to data mining</em><span>&nbsp;</span>and through an end to end data mining application we understand and experience in our Colab notebooks all the stages of a data mining pipeline. At the same time we (a) review essential Python language coding skills, set up of your computing environment that you need to complete this course and (b) review elements of probability and statistics necessary for the remainder of the course.</td>
<td>GERON Chapter 1</td>
</tr>
<tr>
<td>2</td>
<td>Almost all the tasks you will be called to perform as data scientists and analysts will have a flavor of<span>&nbsp;</span><em>supervised learning</em>. Here we start with this learning problem for regression.</td>
<td>GERON Chapter2</td>
</tr>
<tr>
<td>3</td>
<td>Staying at supervised learning, we will learn how to (a) pose the Maximum Likelihood Estimation (MLE) problem that optimizes the parameters (b) solve the MLE via an algorithm that is the workhorse of modern machine learning: the<span>&nbsp;</span><em>stochastic gradient descent</em>.</td>
<td>GERON Chapter 4</td>
</tr>
<tr>
<td>4</td>
<td>We continue with classical classification algorithms and learn how to interpret key performance metrics that arise in such problems.</td>
<td>GERON Chapter 3</td>
</tr>
<tr>
<td>5.1</td>
<td><em>Decision Trees</em><span>&nbsp;</span>are probably the most versatile and extensively used tools for data mining. We start with a review of entropy and deep dive on how they work.</td>
<td>GERON Chapter 6</td>
</tr>
<tr>
<td>5.2</td>
<td><em>Random Forests</em><span>&nbsp;</span>and in general<span>&nbsp;</span><em>Ensemble Methods</em><span>&nbsp;</span>are a natural conceptual extension of decision trees. They can still handle massive datasets<span>&nbsp;</span><em>and</em><span>&nbsp;</span>offer partially<span>&nbsp;</span><em>explainable</em><span>&nbsp;</span>decisions.</td>
<td>GERON Chapter 7</td>
</tr>
<tr>
<td>6</td>
<td><strong>Good luck in your Midterm</strong></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>We now expand into<span>&nbsp;</span><em>Deep neural networks</em><span>&nbsp;</span>that are developed bottom up from the perceptron algorithm and logistic regression. We use the Tensorflow playground to understand the tradeoffs between classical and deep architectures and why deep neural networks dominate in unstructured big data applications today.</td>
<td>GERON Chapter 10</td>
</tr>
<tr>
<td>8</td>
<td>We review one of the most popular DNN architectures in use today: CNNs. They are instrumental to tasks involving feature extraction from images / video.</td>
<td>GERON Chapter 14</td>
</tr>
<tr>
<td>9</td>
<td>We now expand to methods that predict on data sequences. We present Recurrent Neural Networks (RNNs) that are heavily used to predict time series data and generate embeddings in natural language processing (NLP).</td>
<td>GERON Chapter 15</td>
</tr>
<tr>
<td>10</td>
<td>What happens if training data are not available or very expensive to acquire ? This week we review unsupervised learning and<span>&nbsp;</span><em>clustering</em><span>&nbsp;</span>approaches such as K-means. We review use cases in anomaly and novelty detection.</td>
<td>GERON Chapter 9 and ULLMAN Chapter 7</td>
</tr>
<tr>
<td>11</td>
<td>What about if we are dealing with neither a classification or regression task ? A common task is matching also known as<span>&nbsp;</span><em>similarity search</em>. Face recognition applications for example use many of the methods we already discussed but at the end they need to return the closest to the query (person of interest) set of images recorded in a video surveillance system. We will discuss<span>&nbsp;</span><em>approximate nearest neighbors</em><span>&nbsp;</span>techniques such as Locally Sensitive Hashing (LSH) and their implementation in Facebook AI Similarity Search (FAISS) or other similar systems.</td>
<td>ULLMAN Chapter 3</td>
</tr>
<tr>
<td>12</td>
<td>Graph and many other representations of a structured data problem, lead to tall or fat data matrices of high dimensionality.<span>&nbsp;</span><em>Dimensionality Reduction</em><span>&nbsp;</span>is commonly applied to improve significantly the signal to noise ratio.</td>
<td>GERON Chapter 8</td>
</tr>
<tr>
<td>13</td>
<td><em>State of the Art Systems</em><span>&nbsp;</span>We close by looking a cloud computing and reviewing the tools and ways of working that you as data scientists need to be familiar with to build data-intensive applications.</td>
<td>GERON Chapter 19 and Notes</td>
</tr>
<tr>
<td>14</td>
<td>This is a review lecture before the final. It also acts as a buffer in case we run late.</td>
<td></td>
</tr>
<tr>
<td>15</td>
<td><strong>Good luck in your final</strong></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="projects">Projects</h2>
<p>Project details will be published soon.</p>
</div>
